{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6478e3-f317-4418-ab1d-964eeed40261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import tensorflow as tf\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f110a0-4aae-464c-bda5-c3da99209236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_dataset_Самолет.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df6959",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828f3d8c-d472-4b17-bc20-913adf9e5e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_lda(df, lda = LinearDiscriminantAnalysis(n_components=None)):    \n",
    "    X = df.drop(columns=['target']).fillna(0)   \n",
    "    y = df['target']    \n",
    "    X_lda = pd.DataFrame(data=lda.fit_transform(X, y), columns=['LDA_Component'])\n",
    "    df['LDA'] = pd.DataFrame(X_lda)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d521dc9-9017-4edf-bd27-e8e6b6de8968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_pca(df, target_col_name, n_components):\n",
    "    target = df[target_col_name]\n",
    "    data = df.drop(columns=[target_col_name])\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    pca_result = pca.fit_transform(data)\n",
    "\n",
    "    pca_df = pd.DataFrame(data=pca_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
    "\n",
    "    pca_df[target_col_name] = target.values\n",
    "\n",
    "    return pca_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595a37fc-b77b-4ae5-9942-58eb57e4b69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_inverse_and_interactions(df, target_column = \"target\"):\n",
    "    eps = 0.00001\n",
    "\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    # Добавляем обратные величины признаков\n",
    "    for column in df.columns:\n",
    "        if column != target_column:\n",
    "            new_column_name = f\"Inverse_{column}\"\n",
    "            new_df[new_column_name] = 1 / (df[column]+eps)\n",
    "    \n",
    "    new_df2 = new_df.copy()\n",
    "    # Добавляем попарные произведения признаков\n",
    "    for i in range(len(new_df.columns)):\n",
    "        for j in range(i + 1, len(new_df.columns)):\n",
    "            if new_df.columns[i] != target_column and new_df.columns[j] != target_column:\n",
    "                new_column_name = f\"{new_df.columns[i]}_{new_df.columns[j]}_Product\"\n",
    "                new_df2[new_column_name] = new_df[new_df.columns[i]] * new_df[new_df.columns[j]]\n",
    "    \n",
    "    return new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b99f63-c634-4fab-bd56-44707c7f65e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_features(df, k_features, train_sz=14455):\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    model = CatBoostClassifier(iterations=300, depth=6, learning_rate=0.1, random_state=42, verbose=0)\n",
    "    model.fit(X.head(train_sz), y.head(train_sz))\n",
    "    feature_importance = model.get_feature_importance()\n",
    "    order = np.flip(np.argsort(np.array(feature_importance)))\n",
    "    best_features = list(np.array(df.columns)[order])[:k_features]\n",
    "\n",
    "    with open ('best_features.txt', 'w') as f:\n",
    "        for l in list(zip(list(np.array(df.columns)[order]), feature_importance[order])):\n",
    "            f.write(str(l[0])+' '+str(l[1])+'\\n')\n",
    "\n",
    "    if not ('target' in best_features):\n",
    "            best_features.append('target')\n",
    "            \n",
    "    return df[best_features]\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "def get_best_features_xgboost(df, k_features):\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df[\"target\"]  \n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    selected_features = feature_importance_df['Feature'].head(k_features).tolist()\n",
    "    df = df[selected_features + ['target']] \n",
    "\n",
    "    with open ('best_features.txt', 'w') as f:\n",
    "        for l in list(zip(feature_importance_df['Feature'].tolist(), feature_importance_df['Importance'].tolist())):\n",
    "            f.write(str(l[0])+' '+str(l[1])+'\\n')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "def get_best_features_sklearn(df, k_features):\n",
    "    X = df.drop(columns=['target']).fillna(0)\n",
    "    y = df[\"target\"] \n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=k_features)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_columns = list(X.columns[selector.get_support()])\n",
    "    df_new = df[selected_columns + ['target']]\n",
    "\n",
    "    with open ('best_features.txt', 'w') as f:\n",
    "        for l in selected_columns:\n",
    "            f.write(l+'\\n')\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def get_pass(df, k_features):               \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913805c4-255d-4cf9-8930-f9b9726bdab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_df(k_features, k_features_preprocess  = 30, verbose = 1, train_sz=14455):\n",
    "    nan_percent = 60\n",
    "    zero_or_nan_percent = 95\n",
    "    \n",
    "    df0 = df.drop(columns=['col1454', 'report_date', 'client_id'])\n",
    "    df0_train = df0.head(train_sz)\n",
    "    nans = np.array((df0_train.isna()).sum()/df0_train.shape[0]*100.0).round()\n",
    "    if verbose>0:\n",
    "        print(f'Удаляем столбцы, где хотя бы {nan_percent}% NaN. Количество до: {nans.shape}', f'количество после:{nans[nans<nan_percent].shape}')\n",
    "    df1 = df0[df0.columns[nans<nan_percent]]\n",
    "    df1_train = df1.head(train_sz)\n",
    "    nz = np.array(((df1_train==0) | (df1_train.isna())).sum()/df0_train.shape[0]*100.0).round()\n",
    "    if verbose>0:\n",
    "        print(f'Удаляем столбцы, где {zero_or_nan_percent}% - нули или NaN. Количество до: {nz.shape}', f'количество после:{nz[nz<zero_or_nan_percent].shape}')\n",
    "    df2 = df1[df1.columns[nz<zero_or_nan_percent]]\n",
    "    df2['target'] = df['target']\n",
    "    \n",
    "    \n",
    "    #df3 = add_inverse_and_interactions(do_lda(get_best_features_xgboost(df2, k_features_preprocess)))\n",
    "    final_df = get_best_features(df2, k_features)\n",
    "    if verbose>0:\n",
    "        print(\"data preprocessing done\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f8ffb",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c02c02a-5541-4adf-873c-cff910959bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros(X.shape[0])\n",
    "    def score(self, X, y):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa294b5-d4d1-4b1b-acc0-ef716c528db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class xgb_model(model):\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    def fit(self, X, y):\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        self.model = xgb.train(**self.model_params, dtrain=dtrain)\n",
    "    def predict(self, X):\n",
    "        dval = xgb.DMatrix(X)\n",
    "        return self.model.predict(dval, ntree_limit=self.model.best_iteration)\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfa694d-5498-4084-a7cc-c4e1886e1a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class lgbm_model(model):\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    def fit(self, X, y):\n",
    "        self.model = lgbm.LGBMRegressor(**self.model_params).fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613c6426-f300-40d0-96c9-0583cc05df99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rf_model(model):\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    def fit(self, X, y):\n",
    "        self.model = RandomForestClassifier(**self.model_params)\n",
    "        self.model.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50208a89-f32a-4934-b4c0-7b53bb4516da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cat_model(model):\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = model_params\n",
    "    def fit(self, X, y):\n",
    "        self.model = CatBoostClassifier(**self.model_params)\n",
    "        self.model.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ed79c8-0737-496e-9669-a6981d15c309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class nn_model(model):\n",
    "    def __init__(self, model_params):\n",
    "        self.model_params = dict(model_params)\n",
    "        self.shape=self.model_params['shape']\n",
    "        del self.model_params['shape']\n",
    "    def fit(self, X, y):\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu', input_shape=self.shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), **self.model_params)\n",
    "        \n",
    "        self.model.fit(X, y, epochs=100, batch_size=512, verbose=0)\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X, verbose=0)\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46321d3-9a37-47e1-a5f0-ce77734a9145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cross_val_model:\n",
    "    def __init__(self, model, model_params, n_splits = 5, random_state = 42):\n",
    "        self.models = [model(model_params) for i in range(n_splits)]\n",
    "        self.n_splits = n_splits\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    def fit(self, X, y):\n",
    "        i = 0\n",
    "        roc_auc_scores = []\n",
    "        for train_idx, val_idx in self.skf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            self.models[i].fit(X_train, y_train)\n",
    "\n",
    "            roc_auc = self.models[i].score(X_val, y_val)\n",
    "            roc_auc_scores.append(roc_auc)\n",
    "            i+=1\n",
    "        \n",
    "        return np.mean(roc_auc_scores), np.min(roc_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8349f9f6-2b6f-42c8-86a5-d7c0e1811d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0feaea0",
   "metadata": {},
   "source": [
    "# Model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a59824b-a041-4c7f-9fe9-882681bd61b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удаляем столбцы, где хотя бы 60% NaN. Количество до: (2663,) количество после:(352,)\n",
      "Удаляем столбцы, где 95% - нули или NaN. Количество до: (352,) количество после:(121,)\n",
      "data preprocessing done\n"
     ]
    }
   ],
   "source": [
    "dataset = get_df(60)\n",
    "\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009a735a-ff00-450c-90e0-c0d7574726bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for CatBoost: (0.9664088900466121, 0.9532359355272435)\n"
     ]
    }
   ],
   "source": [
    "cat_params = {\n",
    "    'iterations':800,\n",
    "    'depth':9,\n",
    "    'learning_rate':0.1,\n",
    "    'random_state':42,\n",
    "    'verbose':0\n",
    "}\n",
    "cat_dataset = {\n",
    "    'size':60,\n",
    "    'norm':False\n",
    "}\n",
    "\n",
    "md = cross_val_model(cat_model, cat_params, n_splits, random_state)\n",
    "print(\"Mean and lowest scores for CatBoost:\",md.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741f1c3c-057c-4588-994d-8220ab31f4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for XGBoost: (0.9719566073693798, 0.9558758423926411)\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'params':{\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': 9,\n",
    "        'learning_rate': 0.03,\n",
    "        'seed':42,\n",
    "         'reg_lambda': 0.12,\n",
    "    },\n",
    "    'num_boost_round':1000}\n",
    "xgb_dataset = {\n",
    "    'size':60,\n",
    "    'norm':False\n",
    "}\n",
    "\n",
    "\n",
    "md = cross_val_model(xgb_model, xgb_params, n_splits, random_state)\n",
    "print(\"Mean and lowest scores for XGBoost:\",md.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f04038e-3bba-4e4e-8e48-ffd42cf355c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удаляем столбцы, где хотя бы 60% NaN. Количество до: (2663,) количество после:(352,)\n",
      "Удаляем столбцы, где 95% - нули или NaN. Количество до: (352,) количество после:(121,)\n",
      "data preprocessing done\n"
     ]
    }
   ],
   "source": [
    "dataset = get_df(100)\n",
    "\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a65a0f-cbcc-4d22-9e43-27d73416d053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for LiteGBM: (0.957596458708786, 0.9478905340482398)\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.1,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "lgbm_dataset = {\n",
    "    'size':100,\n",
    "    'norm':False\n",
    "}\n",
    "\n",
    "md = cross_val_model(lgbm_model, lgbm_params, n_splits, random_state)\n",
    "print(\"Mean and lowest scores for LiteGBM:\",md.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61260ef2-2c1c-4db5-a34b-6c7edd58b8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удаляем столбцы, где хотя бы 60% NaN. Количество до: (2663,) количество после:(352,)\n",
      "Удаляем столбцы, где 95% - нули или NaN. Количество до: (352,) количество после:(121,)\n",
      "data preprocessing done\n"
     ]
    }
   ],
   "source": [
    "dataset = get_df(80).fillna(-1)\n",
    "\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target']\n",
    "X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b02603-4483-4e64-b52f-0a49b6299e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for Neural Network: (0.882550491386391, 0.816243625690721)\n"
     ]
    }
   ],
   "source": [
    "nn_params = {\n",
    "    'loss': 'binary_crossentropy', \n",
    "    'metrics':['accuracy'],\n",
    "    'shape':(X.shape[1],)\n",
    "}\n",
    "nn_dataset = {\n",
    "    'size':80,\n",
    "    'norm':True\n",
    "}\n",
    "\n",
    "md = cross_val_model(nn_model, nn_params, n_splits, random_state)\n",
    "print(\"Mean and lowest scores for Neural Network:\",md.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "006c6b8a-d740-45b8-9bd1-6406c3141c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for Random Forest: (0.9745959692229491, 0.9581591158771541)\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'criterion': 'entropy',\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 2000\n",
    "}\n",
    "rf_dataset = {\n",
    "    'size':80,\n",
    "    'norm':True\n",
    "}\n",
    "\n",
    "md = cross_val_model(rf_model, rf_params, n_splits, random_state)\n",
    "print(\"Mean and lowest scores for Random Forest:\",md.fit(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21083833",
   "metadata": {},
   "source": [
    "# Model stacking and creating the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "063f1ff2-ab1a-40d4-a83a-811c91760a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(size=60, norm=False):\n",
    "    dataset = get_df(size, verbose=0)\n",
    "    if norm:\n",
    "        dataset = dataset.fillna(-1)\n",
    "    X = dataset.drop('target', axis=1)\n",
    "    y = dataset['target']\n",
    "    if norm:\n",
    "        X = (X - X.mean()) / X.std()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d16eda-48c1-4c05-a5bf-d5348cbd2023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class master_model:\n",
    "    def __init__(self):\n",
    "        self.models = [xgb_model(xgb_params), lgbm_model(lgbm_params), rf_model(rf_params)]\n",
    "        self.dataset_params = [xgb_dataset, lgbm_dataset, rf_dataset]\n",
    "        self.max_size = 0\n",
    "        self.n = 3\n",
    "        for i in range(self.n):\n",
    "            self.max_size = max(self.max_size, self.dataset_params[i]['size'])\n",
    "    \n",
    "    def subset(self, X, Xnorm, i):\n",
    "        #print(X.columns)\n",
    "        if self.dataset_params[i]['norm']:\n",
    "            return Xnorm.iloc[:,:self.dataset_params[i]['size']]\n",
    "        else:\n",
    "            return X.iloc[:,:self.dataset_params[i]['size']]\n",
    "    \n",
    "    def fit_submodels(self, X, Xnorm, y):\n",
    "        for i in range(self.n):\n",
    "            self.models[i].fit(self.subset(X, Xnorm, i), y)\n",
    "            #print(\"submodel\", i, \"fit\")\n",
    "    \n",
    "    def fit(self, X, Xnorm, y, model_params):\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(self.n):\n",
    "            data[i] = self.models[i].predict(self.subset(X, Xnorm, i))\n",
    "        self.model = CatBoostClassifier(**model_params)\n",
    "        self.model.fit(data, y)\n",
    "        \n",
    "    def predict_with_submodels(self, X, Xnorm):\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(self.n):\n",
    "            data[i] = self.models[i].predict(self.subset(X, Xnorm, i))\n",
    "        return data\n",
    "    \n",
    "    def predict(self, X, Xnorm):\n",
    "        data = self.predict_with_submodels(X, Xnorm)\n",
    "        return self.model.predict_proba(data)[:, 1]\n",
    "    \n",
    "    def score_with_submodels(self, X, Xnorm, y):\n",
    "        y_pred = self.predict_with_submodels(X, Xnorm)\n",
    "        return [roc_auc_score(y, y_pred.iloc[:, i]) for i in range(self.n)]\n",
    "    \n",
    "    def score(self, X, Xnorm, y):\n",
    "        y_pred = self.predict(X, Xnorm)\n",
    "        return roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ab784fb-5703-4281-94dd-a4c80425c861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cross_val_master_model:\n",
    "    def __init__(self, n_splits = 5, random_state = 42):\n",
    "        self.models = [master_model() for i in range(n_splits)]\n",
    "        self.skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        \n",
    "    def fit_submodels(self):\n",
    "        X, y = prepare_data(self.models[0].max_size, False)\n",
    "        Xnorm, _ = prepare_data(self.models[0].max_size, True)\n",
    "        #print(\"data prepared\")\n",
    "        i = 0\n",
    "        roc_auc_scores = []\n",
    "        for train_idx, val_idx in self.skf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            Xnorm_train, Xnorm_val = Xnorm.iloc[train_idx], Xnorm.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.models[i].fit_submodels(X_train, Xnorm_train, y_train)\n",
    "            #print(\"submodels fit\")\n",
    "\n",
    "            roc_auc = self.models[i].score_with_submodels(X_val, Xnorm_val, y_val)\n",
    "            roc_auc_scores.append(roc_auc)\n",
    "            i+=1\n",
    "\n",
    "        return roc_auc_scores\n",
    "    \n",
    "    def fit_model(self, params):\n",
    "        X, y = prepare_data(self.models[0].max_size, False)\n",
    "        Xnorm, _ = prepare_data(self.models[0].max_size, True)\n",
    "        #print(\"data prepared\")\n",
    "        i = 0\n",
    "        roc_auc_scores = []\n",
    "        for train_idx, val_idx in self.skf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            Xnorm_train, Xnorm_val = Xnorm.iloc[train_idx], Xnorm.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.models[i].fit(X_train, Xnorm_train, y_train, params)\n",
    "            #print(\"model fit\")\n",
    "\n",
    "            roc_auc = self.models[i].score(X_val, Xnorm_val, y_val)\n",
    "            roc_auc_scores.append(roc_auc)\n",
    "            i+=1\n",
    "\n",
    "        return np.mean(roc_auc_scores), np.min(roc_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b88568ac-1a87-40a4-b9b6-c6e882eb0bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "md = cross_val_master_model()\n",
    "md.fit_submodels()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "155691d5-56c3-45b4-b08f-46d8e43b20c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and lowest scores for the full model: (0.9751173545554417, 0.9581652647285488)\n"
     ]
    }
   ],
   "source": [
    "master_params = {\n",
    "    'iterations':200,\n",
    "    'depth':6,\n",
    "    'learning_rate':0.1,\n",
    "    'random_state':41,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Mean and lowest scores for the full model:\",md.fit_model(master_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50345fe0",
   "metadata": {},
   "source": [
    "## Forming submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ce49ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_dataset_Самолет.csv\")\n",
    "train_sz = df.shape[0]\n",
    "df2 = pd.read_csv(\"test.csv\", sep=';')\n",
    "test_sz = df2.shape[0]\n",
    "ids = df2['id']\n",
    "df = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f49677-182c-42fb-827f-1451705085e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "md = master_model()\n",
    "\n",
    "X, y = prepare_data(md.max_size, False)\n",
    "Xnorm, _ = prepare_data(md.max_size, True)\n",
    "\n",
    "X_train, X_test = X.head(train_sz), X.tail(test_sz)\n",
    "Xnorm_train, Xnorm_test = Xnorm.head(train_sz), Xnorm.tail(test_sz)\n",
    "y_train = y.head(train_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc346c95-2cf3-4ed3-a2bb-a5b0fc099a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "md.fit_submodels(X_train, Xnorm_train, y_train)\n",
    "md.fit(X_train, Xnorm_train, y_train, master_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae911d93-a1c8-4aad-87ad-8c532e4c4253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = md.predict(X_test, Xnorm_test)\n",
    "df2['target'] = pred\n",
    "df2[['id', 'target']].to_csv('result.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
